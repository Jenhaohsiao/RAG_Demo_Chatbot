"""
Content Moderation Service
ä½¿ç”¨ Gemini Safety API æª¢æŸ¥å…§å®¹å®‰å…¨æ€§ï¼Œé˜»æ“‹æœ‰å®³æˆ–ä¸ç•¶å…§å®¹
"""
import logging
from enum import Enum
from typing import Optional
from dataclasses import dataclass

import google.generativeai as genai

logger = logging.getLogger(__name__)


class ModerationStatus(str, Enum):
    """å…§å®¹å¯©æ ¸ç‹€æ…‹"""
    APPROVED = "APPROVED"  # å…§å®¹å®‰å…¨ï¼Œå…è¨±è™•ç†
    BLOCKED = "BLOCKED"    # å…§å®¹è¢«é˜»æ“‹ï¼ŒåŒ…å«æœ‰å®³ææ–™


class HarmCategory(str, Enum):
    """Gemini Safety API å±å®³é¡åˆ¥"""
    HARASSMENT = "HARM_CATEGORY_HARASSMENT"                    # é¨·æ“¾
    HATE_SPEECH = "HARM_CATEGORY_HATE_SPEECH"                 # ä»‡æ¨è¨€è«–
    SEXUALLY_EXPLICIT = "HARM_CATEGORY_SEXUALLY_EXPLICIT"     # æ€§ç›¸é—œå…§å®¹
    DANGEROUS_CONTENT = "HARM_CATEGORY_DANGEROUS_CONTENT"     # å±éšªå…§å®¹


@dataclass
class ModerationResult:
    """
    å…§å®¹å¯©æ ¸çµæœ
    
    Attributes:
        status: å¯©æ ¸ç‹€æ…‹ (APPROVED/BLOCKED)
        blocked_categories: è¢«é˜»æ“‹çš„å±å®³é¡åˆ¥åˆ—è¡¨ï¼ˆå¦‚æœæœ‰ï¼‰
        reason: é˜»æ“‹åŸå› èªªæ˜ï¼ˆå¦‚æœè¢«é˜»æ“‹ï¼‰
    """
    status: ModerationStatus
    blocked_categories: list[str]
    reason: Optional[str] = None
    
    @property
    def is_approved(self) -> bool:
        """å…§å®¹æ˜¯å¦é€šéå¯©æ ¸"""
        return self.status == ModerationStatus.APPROVED
    
    @property
    def is_blocked(self) -> bool:
        """å…§å®¹æ˜¯å¦è¢«é˜»æ“‹"""
        return self.status == ModerationStatus.BLOCKED


class ModerationError(Exception):
    """å…§å®¹å¯©æ ¸éç¨‹ä¸­ç™¼ç”Ÿçš„éŒ¯èª¤"""
    pass


class ModerationService:
    """
    å…§å®¹å¯©æ ¸æœå‹™
    ä½¿ç”¨ Gemini Safety API æª¢æŸ¥æ–‡å­—å…§å®¹çš„å®‰å…¨æ€§
    """
    
    def __init__(self, api_key: Optional[str]):
        """
        åˆå§‹åŒ–å¯©æ ¸æœå‹™
        
        Args:
            api_key: Gemini API é‡‘é‘°
            
        Raises:
            ModerationError: å¦‚æœ API é‡‘é‘°ç„¡æ•ˆæˆ–åˆå§‹åŒ–å¤±æ•—
        """
        self.api_key = api_key
        # è¨­å®šå®‰å…¨è¨­å®š - è¨­ç‚ºBLOCK_NONEï¼Œç”±æˆ‘å€‘è‡ªå·±çš„é‚è¼¯åˆ¤æ–·
        self.safety_settings = {
            HarmCategory.HARASSMENT: "BLOCK_NONE",
            HarmCategory.HATE_SPEECH: "BLOCK_NONE", 
            HarmCategory.SEXUALLY_EXPLICIT: "BLOCK_NONE",
            HarmCategory.DANGEROUS_CONTENT: "BLOCK_NONE",
        }
        if not api_key:
            logger.warning("ModerationService initialized without API key; moderation will require user-provided key")
            self.model = None
            return
        try:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(
                model_name='gemini-2.0-flash',
                safety_settings=self.safety_settings
            )
            logger.info("Content moderation service initialized successfully")
        except Exception as e:  # noqa: BLE001
            logger.error(f"Failed to initialize moderation service: {e}")
            self.model = None
    
    def check_content_safety(self, text: str, source_reference: str = "unknown", academic_mode: bool = False) -> ModerationResult:
        """
        æª¢æŸ¥æ–‡å­—å…§å®¹çš„å®‰å…¨æ€§
        åªé˜»æ“‹çœŸæ­£æœ‰å®³çš„å…§å®¹ï¼šé¨·æ“¾ã€ä»‡æ¨è¨€è«–ã€æ€§ç›¸é—œå…§å®¹ã€å±éšªå…§å®¹
        
        Args:
            text: è¦æª¢æŸ¥çš„æ–‡å­—å…§å®¹
            source_reference: å…§å®¹ä¾†æºåƒè€ƒï¼ˆæª”æ¡ˆåç¨±æˆ– URLï¼‰ç”¨æ–¼æ—¥èªŒè¨˜éŒ„
            academic_mode: å­¸è¡“æ¨¡å¼ï¼ˆç¾åœ¨åŸºæœ¬ä¸Šä¸èµ·ä½œç”¨ï¼Œå› ç‚ºæˆ‘å€‘å·²ç¶“å¾ˆå¯¬é¬†äº†ï¼‰
            
        Returns:
            ModerationResult: å¯©æ ¸çµæœï¼ŒåŒ…å«ç‹€æ…‹å’Œè¢«é˜»æ“‹çš„é¡åˆ¥
            
        Raises:
            ModerationError: å¦‚æœå¯©æ ¸éç¨‹å¤±æ•—
        """
        if not text or not text.strip():
            logger.info(f"Empty content provided for moderation from '{source_reference}', approving")
            return ModerationResult(
                status=ModerationStatus.APPROVED,
                blocked_categories=[],
                reason=None
            )
        
        try:
            logger.info(f"Checking content safety for '{source_reference}' ({len(text)} characters) - blocking harmful and explicit content")
            
            # ğŸ”¥ STEP 1: æª¢æŸ¥ URL æœ¬èº«æ˜¯å¦ç‚ºå·²çŸ¥çš„æˆäººç¶²ç«™
            url_check_result = self._check_url_domain(source_reference)
            if url_check_result.is_blocked:
                logger.warning(f"URL blocked for '{source_reference}': {url_check_result.reason}")
                return url_check_result
            
            # ğŸ”¥ STEP 2: æª¢æŸ¥å…§å®¹æ˜¯å¦åŒ…å«æ˜ç¢ºçš„è‰²æƒ…/æˆäººé—œéµå­—
            explicit_check = self._check_explicit_keywords(text, source_reference)
            if explicit_check.is_blocked:
                logger.warning(f"Explicit content blocked for '{source_reference}': {explicit_check.reason}")
                return explicit_check
            
            # ğŸ”¥ STEP 3: æª¢æŸ¥æ¥µç«¯æœ‰å®³å…§å®¹ï¼ˆæš´åŠ›ã€ä»‡æ¨ã€å±éšªå…§å®¹ï¼‰
            harmful_result = self._check_only_harmful_content(text)
            if harmful_result.is_blocked:
                logger.warning(f"Harmful content blocked for '{source_reference}': {harmful_result.reason}")
                return harmful_result
            
            # å…§å®¹é€šéæ‰€æœ‰æª¢æŸ¥
            logger.info(f"Content approved for '{source_reference}' - no harmful or explicit content detected")
            return ModerationResult(
                status=ModerationStatus.APPROVED,
                blocked_categories=[],
                reason=None
            )
            
        except Exception as e:
            logger.error(f"Content moderation failed for '{source_reference}': {e}")
            # éŒ¯èª¤æ™‚é»˜èªæ‰¹å‡†ï¼Œé¿å…èª¤æ””
            logger.warning(f"Moderation error, defaulting to APPROVED for '{source_reference}'")
            return ModerationResult(
                status=ModerationStatus.APPROVED,
                blocked_categories=[],
                reason=None
            )
    
    def _check_url_domain(self, source_reference: str) -> ModerationResult:
        """
        æª¢æŸ¥ URL åŸŸåæ˜¯å¦ç‚ºå·²çŸ¥çš„æˆäºº/è‰²æƒ…ç¶²ç«™
        
        Args:
            source_reference: å…§å®¹ä¾†æºï¼ˆå¯èƒ½åŒ…å« URLï¼‰
            
        Returns:
            ModerationResult: å¯©æ ¸çµæœ
        """
        from urllib.parse import urlparse
        
        source_lower = source_reference.lower()
        
        # å·²çŸ¥çš„æˆäººç¶²ç«™åŸŸåé—œéµå­—
        adult_domains = [
            "xvideos", "pornhub", "xnxx", "redtube", "youporn", 
            "porn", "xxx", "sex", "adult", "erotic", "hentai",
            "xhamster", "spankbang", "tube8", "xtube", "beeg",
            "av", "è‰²æƒ…", "æˆäºº", "18ç¦", "é™åˆ¶ç´š"
        ]
        
        # æª¢æŸ¥ URL ä¸­æ˜¯å¦åŒ…å«æˆäººç¶²ç«™é—œéµå­—
        for domain_keyword in adult_domains:
            if domain_keyword in source_lower:
                reason = f"æª¢æ¸¬åˆ°æˆäººç¶²ç«™ URL: åŒ…å« '{domain_keyword}'"
                logger.warning(f"Adult domain detected: {reason}")
                return ModerationResult(
                    status=ModerationStatus.BLOCKED,
                    blocked_categories=["SEXUALLY_EXPLICIT_URL"],
                    reason=reason
                )
        
        # é€šéæª¢æŸ¥
        return ModerationResult(
            status=ModerationStatus.APPROVED,
            blocked_categories=[],
            reason=None
        )
    
    def _check_explicit_keywords(self, text: str, source_reference: str) -> ModerationResult:
        """
        æª¢æŸ¥å…§å®¹æ˜¯å¦åŒ…å«æ˜ç¢ºçš„è‰²æƒ…/æˆäººé—œéµå­—
        é€™å€‹æª¢æŸ¥æ¯” _check_only_harmful_content æ›´å…¨é¢
        
        Args:
            text: è¦æª¢æŸ¥çš„æ–‡å­—å…§å®¹
            source_reference: å…§å®¹ä¾†æºåƒè€ƒ
            
        Returns:
            ModerationResult: å¯©æ ¸çµæœ
        """
        content_lower = text.lower()
        
        # æ˜ç¢ºçš„è‰²æƒ…/æˆäººå…§å®¹é—œéµå­—ï¼ˆè‹±æ–‡ï¼‰- ä½¿ç”¨æ›´éˆæ´»çš„åŒ¹é…
        explicit_keywords_en = [
            "porn", "xxx", "nude photo", "adult video", 
            "sex video", "erotic", "pornograph",
            "live cam", "cam girl", "webcam sex",
            "strip club", "escort service", "prostitution"
        ]
        
        # æ˜ç¢ºçš„è‰²æƒ…/æˆäººå…§å®¹é—œéµå­—ï¼ˆä¸­æ–‡ï¼‰
        explicit_keywords_zh = [
            "è‰²æƒ…", "æˆäººå½±ç‰‡", "Aç‰‡", "AVå¥³å„ª", "è£¸ç…§",
            "æˆäººç›´æ’­", "è‰²æƒ…ç›´æ’­", "æ´äº¤", "æ€§æœå‹™",
            "æƒ…è‰²ç¶²ç«™", "æˆäººç¶²ç«™", "é»ƒç‰‡", "æ¯›ç‰‡"
        ]
        
        all_keywords = explicit_keywords_en + explicit_keywords_zh
        found_keywords = []
        
        for keyword in all_keywords:
            if keyword in content_lower:
                found_keywords.append(keyword)
        
        # å¦‚æœæ‰¾åˆ°å¤šå€‹é—œéµå­—ï¼Œæ›´ç¢ºå®šæ˜¯æˆäººå…§å®¹
        if len(found_keywords) >= 2:
            reason = f"æª¢æ¸¬åˆ°æ˜ç¢ºçš„æˆäººå…§å®¹é—œéµå­—: {', '.join(found_keywords[:3])}"
            logger.warning(f"Explicit content detected: {reason}")
            return ModerationResult(
                status=ModerationStatus.BLOCKED,
                blocked_categories=["SEXUALLY_EXPLICIT"],
                reason=reason
            )
        
        # å¦‚æœåªæ‰¾åˆ°ä¸€å€‹é—œéµå­—ï¼Œæª¢æŸ¥æ˜¯å¦åœ¨æ¨™é¡Œã€metaæ¨™ç±¤ç­‰é‡è¦ä½ç½®
        if len(found_keywords) == 1:
            # æª¢æŸ¥æ˜¯å¦åœ¨å‰ 500 å€‹å­—ç¬¦ä¸­ï¼ˆé€šå¸¸æ˜¯æ¨™é¡Œã€æè¿°ç­‰ï¼‰
            if found_keywords[0] in content_lower[:500]:
                reason = f"åœ¨é é¢é‡è¦ä½ç½®æª¢æ¸¬åˆ°æˆäººå…§å®¹é—œéµå­—: {found_keywords[0]}"
                logger.warning(f"Explicit keyword in important position: {reason}")
                return ModerationResult(
                    status=ModerationStatus.BLOCKED,
                    blocked_categories=["SEXUALLY_EXPLICIT"],
                    reason=reason
                )
        
        # é€šéæª¢æŸ¥
        return ModerationResult(
            status=ModerationStatus.APPROVED,
            blocked_categories=[],
            reason=None
        )
    
    def _check_only_harmful_content(self, text: str) -> ModerationResult:
        """
        åªæª¢æŸ¥çœŸæ­£æœ‰å®³çš„å…§å®¹ï¼Œç”¨éå¸¸åš´æ ¼çš„æ¨™æº–
        
        Args:
            text: è¦æª¢æŸ¥çš„æ–‡å­—å…§å®¹
            
        Returns:
            ModerationResult: å¯©æ ¸çµæœ
        """
        content_lower = text.lower()
        
        # éå¸¸æ˜ç¢ºçš„æœ‰å®³é—œéµå­— - åªæœ‰é€™äº›æ‰æœƒè¢«é˜»æ“‹
        extremely_harmful_keywords = {
            "harassment": [
                "äººè‚‰æœç´¢", "äººè‚‰æœå°‹", "é¨·æ“¾å¨è„…", "äººèº«å¨è„…", "æåš‡å¨è„…",
                "æˆ‘è¦æ®ºäº†ä½ ", "æˆ‘è¦å‚·å®³ä½ ", "æ­»å»", "å»æ­»"
            ],
            "hate_speech": [
                "ç¨®æ—æ¸…æ´—", "æ»…çµ•ç¨®æ—", "ä»‡æ¨çŠ¯ç½ªæŒ‡å°", "æ¥µç«¯ä»‡æ¨è¨€è«–"
            ],
            "sexually_explicit": [
                "å…’ç«¥è‰²æƒ…", "æœªæˆå¹´è‰²æƒ…", "æ€§è™å¾…å…’ç«¥", "å¼·æš´æè¿°"
            ],
            "dangerous": [
                "è£½é€ ç‚¸å½ˆæ•™ç¨‹", "ææ€–æ”»æ“Šè¨ˆç•«", "æŠ•æ¯’æ–¹æ³•", "è‡ªæ®ºè©³ç´°æŒ‡å°",
                "å¦‚ä½•æ®ºäºº", "è£½æ¯’æ•™ç¨‹", "çˆ†ç‚¸ç‰©è£½ä½œ"
            ]
        }
        
        blocked_categories = []
        found_keywords = []
        
        for category, keywords in extremely_harmful_keywords.items():
            for keyword in keywords:
                if keyword in content_lower:
                    blocked_categories.append(category)
                    found_keywords.append(keyword)
        
        if blocked_categories:
            reason = f"æª¢æ¸¬åˆ°æ˜ç¢ºæœ‰å®³å…§å®¹é—œéµå­—ï¼š{', '.join(found_keywords)}"
            return ModerationResult(
                status=ModerationStatus.BLOCKED,
                blocked_categories=blocked_categories,
                reason=reason
            )
        
        # é€šéæª¢æŸ¥
        return ModerationResult(
            status=ModerationStatus.APPROVED,
            blocked_categories=[],
            reason=None
        )
    
    def _extract_blocked_categories(self, feedback) -> list[str]:
        """
        å¾ prompt_feedback ä¸­æå–è¢«é˜»æ“‹çš„é¡åˆ¥
        
        Args:
            feedback: Gemini API çš„ prompt_feedback ç‰©ä»¶
            
        Returns:
            list[str]: è¢«é˜»æ“‹çš„å±å®³é¡åˆ¥åˆ—è¡¨
        """
        blocked = []
        
        if hasattr(feedback, 'safety_ratings'):
            for rating in feedback.safety_ratings:
                if hasattr(rating, 'category') and hasattr(rating, 'probability'):
                    # å°‡ Gemini çš„é¡åˆ¥è½‰æ›ç‚ºæˆ‘å€‘çš„æ ¼å¼
                    category_name = str(rating.category).replace('HarmCategory.', '')
                    
                    # æª¢æŸ¥æ¦‚ç‡æ˜¯å¦ç‚º HIGHï¼ˆä¸å†é˜»æ“‹ MEDIUMï¼‰
                    prob = str(rating.probability)
                    if prob in ['HIGH', 'HARM_PROBABILITY_HIGH']:
                        blocked.append(category_name)
        
        return blocked if blocked else ["UNSPECIFIED"]
    
    def _check_safety_ratings(self, safety_ratings) -> list[str]:
        """
        æª¢æŸ¥å®‰å…¨è©•ç´šæ˜¯å¦æœ‰é«˜é¢¨éšªé …ç›®
        
        Args:
            safety_ratings: Gemini API çš„ safety_ratings åˆ—è¡¨
            
        Returns:
            list[str]: é«˜é¢¨éšªé¡åˆ¥åˆ—è¡¨
        """
        high_risk = []
        
        for rating in safety_ratings:
            if hasattr(rating, 'category') and hasattr(rating, 'probability'):
                category_name = str(rating.category).replace('HarmCategory.', '')
                prob = str(rating.probability)
                
                # åªæœ‰ HIGH æ¦‚ç‡è¦–ç‚ºé«˜é¢¨éšªï¼ˆä¸å†åŒ…å« MEDIUMï¼‰
                if prob in ['HIGH', 'HARM_PROBABILITY_HIGH']:
                    high_risk.append(category_name)
        
        return high_risk


# ä¾¿åˆ©å‡½æ•¸ï¼šå¿«é€Ÿæª¢æŸ¥å…§å®¹å®‰å…¨æ€§
def check_content_safety(
    text: str,
    api_key: str,
    source_reference: str = "unknown",
    academic_mode: bool = False
) -> ModerationResult:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå¿«é€Ÿæª¢æŸ¥å…§å®¹å®‰å…¨æ€§
    
    Args:
        text: è¦æª¢æŸ¥çš„æ–‡å­—å…§å®¹
        api_key: Gemini API é‡‘é‘°
        source_reference: å…§å®¹ä¾†æºåƒè€ƒ
        academic_mode: æ˜¯å¦ä½¿ç”¨å­¸è¡“æ¨¡å¼ï¼ˆæ›´å¯¬é¬†çš„å¯©æ ¸æ¨™æº–ï¼‰
        
    Returns:
        ModerationResult: å¯©æ ¸çµæœ
        
    Raises:
        ModerationError: å¦‚æœå¯©æ ¸å¤±æ•—
    """
    service = ModerationService(api_key)
    return service.check_content_safety(text, source_reference, academic_mode)
